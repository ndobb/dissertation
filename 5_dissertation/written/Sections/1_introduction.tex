\documentclass[../main.tex]{subfiles}

\begin{document}

\section{Problem}

Randomized controlled trials serve a critical role in the generation of medical evidence and furthering of biomedical research. In order to identify patients for clinical trials, investigators publish eligibility criteria, such as past history of certain conditions, treatments, or laboratory tests. These eligibility criteria are typically composed in free-text, consisting of inclusion and exclusion criteria. Patients meeting a trial's eligibility criteria are considered potential candidates for recruitment. 

Recruitment of participants remains a major barrier to successful trial completion \cite{richesson2013electronic}, so generating a large pool of potential candidates is often necessary. Manual chart review of hundreds or thousands of patients to determine a candidate pool, however, can be prohibitively labor- and time-intensive. Cohort discovery tools such as Leaf \cite{dobbins2019leaf} and i2b2 \cite{murphy2010serving} may be used, providing researchers with a relatively simple drag-and-drop graphical interface in their web browser to create database queries to find potential patients in electronic health records (EHR) \cite{johnson2014use}. Learning how to use such tools nevertheless presents a challenge, as graphically-represented concepts may not align with researchers' understanding of biomedical phenomena or trial eligibility criteria. In addition, certain complex queries may simply be impossible to execute due to structural limitations on the types of possible queries presented in these tools, such as complex temporal or nested sequences of events \cite{deshmukh2009evaluating}.

An alternative approach is the use of natural language processing (NLP) to automatically analyze eligibility criteria and generate database queries to find patients in EHRs. NLP-based approaches have the advantage of obviating potential learning curves of tools such as Leaf, while leveraging existing eligibility criteria composed in a format researchers are already familiar with. Previous research in the use of NLP for trial recruitment \cite{yuan2019criteria2query, soni2020patient, fang2022combining, zhang2020deepenroll, chen2019clinical, patrao2015recruit, dhayne2021emr2vec, liu2021evaluating, xiong2019cohort} has shown promise but also limitations, preventing more widespread use for recruitment. For example, eligibility criteria often refer to non-specific criteria \cite{wang2017classifying, ross2010analysis}, such as "conditions affecting respiratory function", which save investigator time by avoiding the need for exhaustive lists of conditions, but also must be reasoned upon to determine. Past research has also largely supported only single, static data models, limiting potential usage to only institutions or researchers with data in particular formats, and preventing future additions or changes to data structure necessitated by changes in clinical workflow, research needs, and so on. In terms of evaluation, past research has also largely evaluated solutions based on metrics such as concept normalization performance, measuring how well applications can map text to coded elements such as ICD-10 or LOINC. While important, these metrics do not address the more important question of how well such tools are able to find patients meeting a given set of criteria.

This work explores the development of a user-friendly, explainable, and generalizable application for cohort discovery from natural language by querying virtually any database schema. We demonstrate that this system is capable of state-of-the-art query generation. We hope believe this system may enable faster discovery of eligible patients for clinical trials and biomedical research in general.

The importance of improving efficiencies in trial recruitment is difficult to overstate. Clinical trials are considered the gold standard of evaluation of new treatments but also extremely costly; for example, the average cost of a Phase 3 trial in the United States ranges from US\$11.5 million to US\$52.9 million \cite{sertkaya2016key}. Much of those costs are due to difficulties in finding and keeping patients enrolled. Systems which stand to improve efficiencies in finding patients eligible for trials using a medium researchers already know well and frequently use - natural language - therefore may also contribute to reducing costs and simplifying processes for enrolling patients. 

The potential impact of this work extends beyond clinical trials. Biomedical research in general very often relies on finding patients meeting certain criteria, whether for retrospective analysis, sample size estimates, preparation to research, and so on. We hope that the methods and application we develop for creating a natural language interface to databases may simplify and streamline this common critical step for a variety of research purposes.

\section{Contributions}

This work explores the development of a novel database query-generation system to identify patients eligible for clinical trials using a natural language interface. The primary contributions of this work are:

\begin{enumerate}
    \item \textit{Annotated Corpora}: this work introduces two new annotated clinical corpora: the LCT corpus and LLF corpus. The LCT corpus contains over 1,000 annotated eligibility criteria documents and captures annotated phenomena important for the task of clinical query generation at a highly granular level \cite{dobbins2022leaf}. These phenomena include clinical events, such as diagnoses, procedures, laboratory tests, vitals, and medications, demographic facets such as sex, ethnicity, and age, as well as abstract, temporal, and qualifying values such as contraindications, indications, temporal sequences, negations, risks, and severities. The LCT corpus is unique in the granularity of its annotation schema and number of annotated documents. The LLF corpus is a subset of 2,000 lines of eligibility criteria from the LCT corpus which includes the original criteria sentence alongside machine-readable intermediate logical representations, or logical forms. To the best of our knowledge, the LLF corpus is the only large publicly available data set of human-annotated clinical trial eligibility criteria as logical forms.
    \item \textit{Model-agnostic query generation}: We introduce a novel database annotation schema and mapping method to enable query generation on virtually any clinical data model. Our system uses a subset of Unified Medical Language System (UMLS) \cite{bodenreider2004unified} concepts to flexibly represent database resources using concepts related to metadata, such as patient identifiers, demographics, and vocabularies.
    \item \textit{Knowledge Base}: Various tasks related to query generation, such as hierarchy navigation (e.g., finding types of surgeries related to cancers), vocabulary and code normalization (e.g., conversion to SNOMED, LOINC, or ICD-10 codes), and reasoning (explained next) necessitate the use of a Knowledge Base (KB). We introduce a graph-based KB which incorporates the UMLS, the Disease Ontology \cite{schriml2012disease}, Symptom Ontology \cite{sayers2010database}, COVID-19 Ontology \cite{sargsyan2020covid}, Potential Drug-Drug Interactions \cite{ayvaz2015toward}, LOINC2HPO \cite{zhang2019semantic}, and the Disease-Symptom Knowledge Base \cite{wang2008automated}, as well as various equivalency mappings not present in the UMLS \cite{icd9_icd10_icd10pcs, icd9dx_snomed, icd9proc_snomed, snomed_icd10}.
    \item \textit{Reasoning upon non-specific criteria}: Many criteria within eligibility criteria are non-specific, and instead need to be first reasoned upon in order to be computable. For example, a criterion may refer to patients "indicated for bariatric surgery", or "who have a disease affecting respiratory function". Using our logical form representations and KB, we demonstrate a system for dynamically reasoning on non-specific criteria.
    \item \textit{Evaluation against a human programmer and actual trial enrollments}: Past systems for automatically identifying patients eligible for clinical trials have largely limited their evaluations to sub-systems such as normalization performance, and thus it is difficult to assess how well such systems actually perform when used with real-world data and trials. In contrast, we evaluate our system using enrollments linked to clinical data for 8 past clinical trials at the University of Washington. We compare the patients found by our generated queries to actual enrolled patients. We then compare our results to those of an human clinical database programmer.
    \item \textit{An interactive web application interface}: we enable interaction with our query generation system via an interactive web-based user interface. Our web application includes a novel chat-like interface system which incorporates streaming interfaces for rapid feedback. The interface enables users to view and edit system interpretations of natural language criteria in an iterative fashion.
\end{enumerate}

\section{Overview}

\textit{Chapter \ref{chap:background}}, \textit{Background}, provides a general overview of clinical trials, as well as past work in cohort discovery and eligibility prediction in relation to NLP. Literature specific to given tasks is also presented briefly in each chapter where applicable. 

\textit{Chapter \ref{chap:lct_corpus}}, \textit{Leaf Clinical Trials corpus}, introduces the first annotated corpus, including motivation, annotation schema, comparison to other corpora, and baseline named entity recognition (NER) and relation extraction performance using multiple neural architectures.

\textit{Chapter \ref{chap:llf_corpus}}, \textit{Leaf Logical Forms corpus}, presents the second annotated corpus and our logical forms annotation schema. The corpus is evaluated using various syntax styles suggested from the literature.

\textit{Chapter \ref{chap:kb}}, \textit{Knowledge Base}, explores the motivation and development of the KB. We discuss each source at a high level and SPARQL queries used for reasoning.

\textit{Chapter \ref{chap:smm}}, \textit{Semantic Metadata Mapping}, describes the motivation and methods we use for dynamically generating queries for eligibility criteria in a data model-agnostic fashion.

\textit{Chapter \ref{chap:query_generation}}, \textit{Query Generation}, explores the development of our methods for query generation, including models used for NER and logical form transformation, normalization, and reasoning. Our system is evaluated in comparison to that of a human database programmer.

\textit{Chapter \ref{chap:web_appplication}}, \textit{Web Application}, examines development of our user-facing web application for interactive cohort discovery.

\textit{Chapter \ref{chap:conclusions}}, \textit{Conclusions}, summarizes this work's primary contributions and possible directions for future research.


\end{document}

