\documentclass[../main.tex]{subfiles}

\begin{document}

\subsection{Natural language processing approaches for cohort discovery}

\noindent In recent years, alternatives to web-based cohort discovery tools for RCT recruitment have also been explored. In particular, various methods using Natural Language Processing (NLP) have been put forth by the research community \cite{yuan2019criteria2query, soni2020patient, fang2022combining, zhang2020deepenroll, chen2019clinical, patrao2015recruit, dhayne2021emr2vec, liu2021evaluating, xiong2019cohort}. NLP-based cohort discovery methods hold unique potential and appeal, as they are theoretically able to leverage existing eligibility criteria described in natural language, a medium researchers and investigators already use and are comfortable with. Recent methods which utilize NLP in some form can generally be grouped into 5 categories:

\begin{enumerate}
    \item{\textbf{Database query generation} to Structured Query Language (SQL) or similar systems using either (a) rules, (b) neural network-based encoder-decoder architectures}, or both.
    \item{\textbf{Document ranking and classification} using clinical notes in terms of relevancy vis-Ã -vis a given eligibility criteria.}
    \item{\textbf{Projection into embeddings} of patient medical history and trial eligibility criteria in a shared vector space and matching via similarity measurement or entailment.}
    \item{\textbf{Logical representations and reasoning} to represent eligibility criteria and patient records, matching by combinations of Semantic Web technologies, ontologies, Description Logics, and rule-based reasoning.}
    \item{A combination of the above.}
\end{enumerate}

\noindent Next we briefly describe recent relevant work in each category.

\textbf{Database query generation} - SQL-based relational databases are widely used both commercially and within academic institutions, and as such SQL is perhaps unsurprisingly often used as a target language in natural language to database query research \cite{dar2019frameworks}. Yuan \textit{et al} developed Criteria2Query, a hybrid information extraction (IE) pipeline and application which uses both rules and machine learning to generate database queries on an OMOP \cite{hripcsak2015observational} (Observation Medical Outcomes Partnership) database. This work was expanded by Fang \textit{et al}, who added functionality for iterative query generation via human correction and adjustment \cite{fang2022combining}. Although not specific to RCTs, other highly relevant recent work on query generation in the biomedical space has been done using encoder-decoder neural architectures for transforming clinical natural language questions into SQL queries \cite{bae2021question, park2021knowledge, wang2020text, pan2021bert, dhayne2021emr2vec}. Park \textit{et al} \cite{park2021knowledge} experimented with transforming medical questions generated in the MIMICSQL dataset \cite{wang2020text} using both SQL and SPARQL queries with varying database schema representations. Bae \textit{et al} similarly experimented with methods for handling typos, misspellings, and abbreviations in generating SQL queries from natural language questions. Pan \textit{et al} \cite{pan2021bert} leveraged intermediate abstract syntax tree-based representations and a SQL grammar-based decoder architecture for dynamic database schema matching. 

\textbf{Document ranking and classification} - Focusing on clinical notes, Chen \textit{et al} \cite{chen2019clinical} used hybrid rule-based heuristics and sentence pattern-matching to detect criteria structure, as well as a combination of neural network-based bi-directional long short-term and conditional random field (biLSTM+CRF) architecture and knowledge graphs using the Unified Medical Language System (UMLS) for determining condition, lab, procedure and drug relationships. Soni and Roberts \cite{soni2020patient} utilized the BERT Transformer architecture \cite{devlin2018bert} and Lucene \cite{lucene} to summarize, rank and classify clinical notes as relevant to a given eligibility criterion, with the most relevant notes predicted to be eligible. 

\textbf{Embedding projections} - Dhayne \textit{et al} \cite{dhayne2021emr2vec} experimented with treating patient-to-RCT matching as a joint embedding and similarity measurement problem while also incorporating the SNOMED-CT ontology to infer basic "is-a" and "has-type" relations between concepts. Similarly, Zhang \textit{et al} used joint patient and eligibility criteria embeddings for entailment prediction, where predicting that a patient can be inferred from a given eligibility criteria equates to eligibility. 

\textbf{Logical representations and reasoning} - Patr{\~a}o \textit{et al} developed Recruit, an ontology-driven trial recruitment system which transformed SQL relational data to Resource Description Framework (RDF) graph-based triples. The RDF triples in turn were made query-able by use of an OWL-based reasoning system \cite{owl} and normalization techniques to infer cancer staging. Building upon earlier work \cite{patel2007matching, huang2013semanticct}, Baader \textit{et al} \cite{baader2018patient} explored the use of Description Logics and ontologies in matching patients in the MIMIC data set \cite{johnson2016mimic} to logical representations of eligibility criteria, for example representing "Diabetes mellitus type 1" as "$\exists_y$.diagnosed\_with(x, y) $\wedge$ Diabetes\_mellitus\_type\_1(y)".

\subsection{Gaps and opportunities}

\noindent Much of the work to date on cohort discovery and RCT eligibility criteria matching has been impressive and impactful in leveraging advances in related research domains. Yet critical gaps remain in terms of practical usability, generalizability, and measurement of performance for these methods in the context of real-world clinical trials and data. 

Among tools and methods for SQL query generation, for example, most efforts to date are capable of generating database queries on only a single database schema, such as OMOP or MIMIC. While the OMOP database schema is widely used in research, this lack of flexibility and adaptability toward other data models limits potential utility, in particular given the widely documented necessity to change and extend the standard OMOP schema to accommodate real-world project needs \cite{belenkaya2021extending, peng2021towards, zoch2021adaption, warner2019hemonc, zhou2013evaluation, shin2019genomic, kwon2019development}. Moreover, most methods for generating SQL queries, particularly those using encoder-decoder architectures, tend to generate relatively simple SQL statements, with few JOINs or nested sub-queries and typically no support for UNION operators and so on. This relative simplicity contrasts with the complexity of real-world clinical databases and it is not clear whether such methods alone are yet viable in an RCT context.

Methods utilizing clinical notes for document ranking show great potential, particularly given the significant amount of untapped information present in free-text as compared to structured data \cite{warrer2012using}. However the use of these systems at enterprise scale or as ad hoc query tools for researchers has been limited, and the number of notes used in these experiments tend to be few (hundreds or low thousands) as compared to the tens of millions of clinical notes stored within many EHRs. 

Efforts using patient and eligibility criteria embeddings, while novel and showing future potential, also have notable limitations: (1) Zhang \textit{et al} assumed that patients who did not enroll in a given trial were not eligible (which may not necessarily be true), and (2) none of the research we are aware of provided sufficient detail on how structured data were transformed into embeddings or what specific data elements (e.g., diagnosis codes, labs) were used, preventing direct reproducibility.  Research in methods using Description Logics and related representations and ontologies, meanwhile, has been largely experimental and untested using large real-world clinical databases. Many works also require domain experts to first manually translate eligibility criteria to logical representations, making them somewhat unrealistic as cohort discovery tools. 

Last, few of the methods described provide support for complex logic, and none support reasoning on non-specific criteria (e.g., "diseases that affect respiratory function"), two phenomena common to eligibility criteria \cite{wang2017classifying, ross2010analysis}. Perhaps most importantly, to the best of our knowledge, only one previous work has been tested in terms of matching patients enrolled in actual clinical trials \cite{zhang2020deepenroll} (with caveats discussed earlier), and none have been directly compared to the capabilities of a human database programmer. 
\end{document}