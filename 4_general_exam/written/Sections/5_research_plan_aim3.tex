\documentclass[../main.tex]{subfiles}

\begin{document}

\subsection{Web Application Development and Evaluation}

Aim 3 will focus on the development of an interactive web application, LeafAI, capable of generating and executing user queries. 

\subsubsection{Application Design}

LeafAI will be developed using a 3-tier architecture similar to Leaf \cite{dobbins2019leaf}: a back-end with clinical and application databases, and server hosting an API (discussed in Aim 2), and a front-end web application. The key innovation of the web application will be its user interface, a chat-like design we expect will be familiar to most users of applications such as Microsoft Teams or Slack.

A chat-like interface for cohort discovery is both novel and a logical design choice given the natural language interface of LeafAI used for query generation. An example of LeafAI's proposed chat interface is shown in Figure \ref{aim3_fig_demo}. As can be seen, we assume that the order of user-provided criteria is intentional and important, and leverage that assumption to both structure queries incrementally to report results line by line, with each reported result (e.g., "421 are aged between 18 and 65") effectively a subset of the preceding result.

\begin{figure}[h!]
  \includegraphics[scale=0.58]{Figures/Aim3/aim3_demo.pdf}  
  \caption{A example mockup of the LeafAI user interface. User-entered criteria are shown in the above left, while LeafAI responses are shown in the lower-right. User criteria are displayed and executed in order, with each count of patients representing a subset of the preceding count.}
\label{aim3_fig_demo}
\end{figure}

It is important to emphasize that LeafAI will respond using a visual form that is chat-\textit{like}, rather than itself being a chat\textit{bot} (i.e., a programmatic conversation agent). While the user interface and query generation methods described in Aim 2 lay a potential foundation for general-purpose question-answering more akin to a conversation agent, we leave that to future work and limit our scope in this project to cohort discovery. The user interface of LeafAI will have the following goals:

\begin{enumerate}
    \item \textbf{Accessible history}. Users will be able to immediately scroll to view previous findings.
    \item \textbf{Rapid feedback and explainability}. LeafAI while perform NER and normalization as users are typing, similar to prefetching search engine responses. This will allow users to preemptively detect concepts and queries which may return unexpected results. LeafAI will also display incremental query results in real-time, providing users faster feedback so users may avoid waiting until all query results are complete.
    \item \textbf{Direct editing of responses enabling iteration}. As LeafAI returns results of patients found, the eligibility criteria used in a query will be directly edit-able, saving users' time and facilitating quick iteration to find intended patients.
\end{enumerate}

\noindent We next describe each goal in detail. \\

\noindent \textbf{Accessible History} \\
Cohort discovery is a form of data exploration. As Derthick and Roth write, "...the data exploration process is not characterized by monotonic progress towards a goal, but rather involves much backtracking and opportunistic goal revision" \cite{derthick2001enhancing}. Put another way, user goals and perceptions may change over the course of their exploration. With ubiquitous vertical scrolling - where more recent actions and utterances are inserted downward while history is preserved upward - chat-like user interfaces facilitate user understanding of past utterances and actions. Persisted, easily viewable history of user utterances and actions enable what Gergle \textit{et al} call "conversational grounding" \cite{gergle2004persistence}, that is, accessible data to guide users to previously acquired findings and information. This history of previous actions can improve the pace of discovery and alleviate the need for users to (often imperfectly) attempt to recall their earlier findings and paths taken \cite{hill1994history, gergle2004persistence}. \\

\noindent \textbf{Rapid Feedback and explainability} \\
Users' sense of system latency and responsiveness can significantly affect their satisfaction in using a tool \cite{li2019effects, arapakis2014impact, shneiderman1984response}. Faster \textit{preemptive} system responses (i.e., informing users' of a possible consequence before they complete an action) can also both save users' time and reduce loads placed upon systems by preventing unnecessary actions \cite{lempel2003predictive, diaz2016search}. LeafAI will employ two general strategies for providing rapid feedback to users, one before queries are executed, and the second while results are being reported during query execution.

First, consider a hypothetical case where a user begins to type a criteria but misspells "Diabetes Mellitus". The user may take seconds or even minutes of additional typing while adding new criteria without knowing of the initial spelling mistake. After the user awaits LeafAI's response, she finds that the query found no patients and is frustrated and confused at the counter-intuitive result, only to finally notice the misspelling, having wasted several minutes. We aim to avoid this scenario by preemptively performing NER and normalization while users are typing. Examples of this are shown in Figure \ref{aim3_fig_mouse_hover}. Named entities found within user criteria will be underlined and interactive, enabling users to better estimate whether their queries will succeed or not.

\begin{figure}[h!]
  \centering
  \includegraphics[scale=0.68]{Figures/Aim3/aim3_mouse_hover.pdf}  
  \caption{Normalized named entities identified in user input before query execution. On the left, the system correctly identified "BMI". On the right, "Diabetes Mellitus" is misspelled, and the user is notified.}
\label{aim3_fig_mouse_hover}
\end{figure}

Second, as LeafAI generates incremental queries and returns results line by line asynchronously, the user interface will show results as they are reported using a streaming interface. As a result, users will not need to wait until all queries are complete (as in tools such as Leaf and i2b2). An example of this is shown in Figure \ref{aim3_fig_query_progress}.

\begin{figure}[h!]
  \centering
  \includegraphics[scale=0.5]{Figures/Aim3/aim3_query_progress.pdf}  
  \caption{A time-lapse style representation of the user interface asynchronously reporting incremental query results, from top to bottom. This will be performed using two streaming interfaces, one from the clinical database to the API, and a second from the API to the web application.}
\label{aim3_fig_query_progress}
\end{figure}

Taken together, these features for rapid feedback and transparency also enable \textit{explainability} of system actions. That is, rather than simply returning a final count of patients meeting criteria, LeafAI will provide information both before and during query execution of how the system interpreted user intent and how it has executed a query (e.g. what concepts it found or did not, misinterpreted, etc.). We currently plan for system language for explaining query results to be generated by templated English expressions mapped to logical form types "slot-filled" using normalized UMLS concept names. By avoiding being a "black box", we expect these features to help gain user trust and understanding of both the system's successes and shortcomings. \\

\noindent \textbf{Direct editing of responses enabling iteration} \\
Data exploration is iterative: users explore, try, and learn over the course of multiple attempts. As discussed, faster, meaningful results also directly affect user satisfaction. To this end, LeafAI will allow users to immediately and directly edit the responses returned by LeafAI. This workflow is depicted in Figure \ref{aim3_fig_feedback_loop}. 

\begin{figure}[h!]
  \centering
  \includegraphics[scale=1]{Figures/Aim3/aim3_feedback_loop.pdf}  
  \caption{An iterative workflow using an example case for adults with Diabetes Mellitus. Users will be able to directly edit results and re-execute their queries while preserving query history, saving user time and preserving previous user actions and findings.}
\label{aim3_fig_feedback_loop}
\end{figure}

For example, after seeing that LeafAI found less patients than expected, a user may realize that she should slightly alter her original query to expand her search. Rather than needing to copy and paste her earlier criteria, instead she will be able to simply click and modify the earlier results.

Additionally, as discussed in Aim 2, LeafAI is capable of reasoning upon non-specific criteria. In certain cases, however, the system's findings may be incomplete, incorrect, or undesired for various reasons. Rather than forcing users to accept imperfect reasoning, however, LeafAI will allow users to directly edit reasoned concepts. An example of this is shown in Figure \ref{aim3_fig_edit}.

\begin{figure}[h!]
  \centering
  \includegraphics[scale=0.68]{Figures/Aim3/aim3_edit.pdf}  
  \caption{An example of a user editing concepts discovered using LeafAI's reasoning system. Users will be able to add or remove reasoned concepts.}
\label{aim3_fig_edit}
\end{figure}

The system's reasoning can thus be described as an optional means of helpfully saving users' time, which can be accepted, edited, or discarded as needed. \\

\noindent \textbf{Model Inference Speed} \\
LeafAI's modules for NER, logical form transformation, lab normalization and so on use large Transformer-based neural models \cite{vaswani2017attention} with millions of parameters. Using these models as-is for inference can be slow, particularly when performed using CPUs rather than more costly but often far faster GPUs (Graphics Processing Units). Delays in inference time in turn can result in poor system latency, affecting user satisfaction. We further assume that institutions or individuals deploying LeafAI may not necessarily have access to GPUs. To improve inference speed on CPUs, we intend to quantize our models, a process for converting 32-bit floating point values within model weights and biases to 8-bit integers. Quantization has been shown to dramatically reduce model storage size and memory usage and improve inference speed while typically showing limited decreases in performance \cite{hubara2017quantized}. 

\subsubsection{Evaluation Metrics}

In Aim 2 we demonstrated that LeafAIs query generation methods achieve current state-of-the-art results on the clinical trials we examined. The question remains, however, whether LeafAI's user experience and satisfaction will improve upon traditional drag-and-drop-based cohort discovery tools. Further, it is not clear whether natural language interfaced-based tools such as LeafAI allow users to more accurately find intended cohorts.

To test this, we will evaluate LeafAI in comparison to Leaf in the following controlled experiment: 

\begin{enumerate}
    \item We will enlist 10 researchers who have no experience using Leaf. Half of the researchers (5/10) will be randomly assigned to use Leaf, while the other half will use LeafAI.
    \item Both groups will by trained using demonstration tutorials for their respective tool to learn how to run queries and understand results.
    \item Groups using Leaf and LeafAI will have access to the same de-identified clinical database\footnote{We will seek an IRB from the University of Washington Human Subjects Division for permission to extract this data}, which will be composed of patients from 5 randomly selected past clinical trials at UW, as well as 50,000 randomly selected patients not enrolled in the trials. Users will be able to see counts of patients but no patient-level information.
    \item Pairs of participants - one from each group - will be tasked to attempt to find patients meeting eligibility criteria for each trial, then save their final query. Each trial will thus have one researcher using Leaf and one researcher using LeafAI to identify patients.
    \item After completing their queries, all 10 participants will be asked to complete 2 surveys: the first, Health-ITUES \cite{yen2010development}, will provide demographic information concerning level of experience in working in clinical research and eligibility screening. The second will be a usability and user satisfaction survey using a 5-point Likert scale.
    \item Our analysis will be conducted by comparing (1) user satisfaction with both applications, (2) number of patients matched between generated queries and actual trial enrollments, similar to Aim 2, and (3) length of time spent generating queries, which we will derive from application log files. The Health-ITUES survey will further allow us to group researchers by background and experience level while comparing results.
\end{enumerate}

\subsubsection{Limitations}

We believe the LeafAI web application will be a significant step forward in cohort discovery in terms of both user experience and query accuracy. However the system will nonetheless have limitations. Within the scope of this project, LeafAI will not include the same features as Leaf, such as the ability to visualize patient demographics or extract row-level data, though we intend to add those in the future. Further, limitations regarding query performance discussed in Aim 2 will also apply in Aim 3, as we expect generated queries to sometimes incorrectly capture eligibility criteria or fail to find the correct patients. LeafAI will also not include a data dictionary or other means of answering possible user questions regarding available clinical data.

\end{document}