
\documentclass[../main.tex]{subfiles}

\begin{document}

Various methods for cohort discovery using natural language processing have been explored. Exploring database query generation methods, Yuan \textit{et al} developed Criteria2Query, a hybrid information extraction (IE) pipeline and application which uses both rules and machine learning to generate database queries on an OMOP \cite{hripcsak2015observational} (Observation Medical Outcomes Partnership) database, later expanded by Fang \textit{et al} \cite{fang2022combining}. Other research has used encoder-decoder neural architectures for transforming clinical natural language questions into SQL queries \cite{bae2021question, park2021knowledge, wang2020text, pan2021bert, dhayne2021emr2vec}. These studies have included exploration of cross-domain transformations, where systems much generalize to unseen database schema\cite{park2021knowledge}, handling of typos and abbreviations\cite{bae2021question}, and the generation and leveraging of intermediate representations between a natural language utterance and final SQL database query.\cite{pan2021bert} 

Beyond database query generation, other methods explored to date include document ranking and classification\cite{chen2019clinical,soni2020patient}, where clinical notes are summarized, ranked and classified as relevant to a given eligibility criterion, and embedding projections for entailment prediction\cite{dhayne2021emr2vec, zhang2020deepenroll}, where predicting that a patient can be inferred from a given eligibility criteria equates to eligibility. Further studies have also explored the use of ontologies and OWL-based reasoning in determining eligiblilty\cite{patel2007matching, huang2013semanticct, baader2018patient, johnson2016mimic, patrao2015recruit}.
    
\subsection*{Gaps and opportunities}

Among methods for database query generation, which we focus on in this study, most efforts to date are capable of generating database queries on only a single database schema, such as OMOP or MIMIC. While the OMOP database schema is widely used in research, this lack of flexibility and adaptability toward other data models limits potential utility, in particular given the widely documented necessity to change and extend the standard OMOP schema to accommodate real-world project needs \cite{belenkaya2021extending, peng2021towards, zoch2021adaption, warner2019hemonc, zhou2013evaluation, shin2019genomic, kwon2019development}. Moreover, most methods, particularly those using encoder-decoder architectures, tend to generate relatively simple SQL statements, with few JOINs or nested sub-queries and typically no support for UNION operators and so on. This relative simplicity contrasts with the complexity of real-world clinical databases and it is not clear whether such methods alone are yet viable in a real-world RCT context. Additionally, few of the methods described provide support for complex logic, and none support reasoning on non-specific criteria (e.g., "diseases that affect respiratory function"), two phenomena common to eligibility criteria \cite{wang2017classifying, ross2010analysis}. Perhaps most importantly, to the best of our knowledge, only one previous work has been tested in terms of matching patients enrolled in actual clinical trials \cite{zhang2020deepenroll}, and none have been directly compared to the capabilities of a human database programmer.

\subsection*{Key Contributions}

We introduce the LeafAI query engine, an application capable of generating database queries for cohort discovery from free-text eligibility descriptions. This work contributes the following:

\begin{enumerate}
    \item{A novel database schema annotation and mapping method to enable \textbf{data model-agnostic} query generation from natural language.}
    \item{Methods for transforming and leveraging \textbf{intermediate logical representations} of eligibility criteria.}
    \item{A \textbf{corpus of human-annotated eligibility criteria and corresponding logical representations} available to the research community\footnote{Will be made available upon article acceptance}.}
    \item{Methods for dynamically \textbf{reasoning upon non-specific criteria} using an integrated knowledge base of biomedical concepts.}
\end{enumerate}

We measure performance of the LeafAI query engine by comparing patients found by generated queries to those enrolled in actual past clinical trials using LeafAI and a human database programmer.

\end{document}