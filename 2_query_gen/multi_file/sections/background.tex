
\documentclass[../main.tex]{subfiles}

\begin{document}

Various methods for cohort discovery using NLP have been explored. Exploring database query generation methods, Yuan \textit{et al} developed Criteria2Query \cite{yuan2019criteria2query}, a hybrid information extraction (IE) pipeline and application which uses both rules and machine learning to generate database queries on an Observation Medical Outcomes Partnership (OMOP) \cite{hripcsak2015observational} database, later expanded by Fang \textit{et al} \cite{fang2022combining}. Other research has used encoder-decoder neural architectures for transforming clinical natural language questions into SQL queries \cite{bae2021question, park2021knowledge, wang2020text, pan2021bert, dhayne2021emr2vec}. These studies have included exploration of cross-domain transformations, where systems must generalize to unseen database schema \cite{park2021knowledge}, handling of typos and abbreviations \cite{bae2021question}, and the generation and leveraging of intermediate representations between a natural language utterance and final SQL database query.\cite{pan2021bert} 

Beyond database query generation, other methods explored to-date include document ranking and classification \cite{chen2019clinical,soni2020patient} where clinical notes are summarized, ranked and classified as relevant to a given eligibility criterion, and embedding projections for entailment prediction \cite{dhayne2021emr2vec, zhang2020deepenroll} where predicting that a patient can be inferred from a given eligibility criteria equates to eligibility. Further studies have also explored the use of ontologies and OWL-based reasoning in determining eligibility \cite{patel2007matching, huang2013semanticct, baader2018patient, johnson2016mimic, patrao2015recruit}.
    
\subsection*{Gaps and opportunities}

Most efforts to-date are capable of generating database queries on only a single database schema, such as OMOP or MIMIC-III \cite{johnson2016mimic}. This lack of flexibility toward other data models limits potential utility to accommodate real-world project needs \cite{belenkaya2021extending, peng2021towards, zoch2021adaption, warner2019hemonc, zhou2013evaluation, shin2019genomic, kwon2019development}, such as adding new database tables to OMOP for cancer staging \cite{belenkaya2021extending}. Moreover, most methods, particularly those using direct text-to-SQL deep learning approaches, tend to generate relatively simple SQL statements with few JOINs or nested sub-queries and typically no support for UNION operators and so on. This relative simplicity contrasts with the complexity of real-world EHR databases, which may contain dozens or even hundreds of tables using various vocabularies and mappings. Thus it is unclear whether such methods are yet viable in a real-world RCT context. Direct text-to-SQL methods have the further limitation of being bound to SQL syntax, and thus incapable of querying other systems such as Fast Healthcare Interoperability Resources (FHIR) \cite{bender2013hl7}. Additionally, few of the methods described provide support for complex logic such as nested Boolean statements or temporal sequences, and none support reasoning on non-specific criteria (e.g., "diseases that affect respiratory function"), phenomena common to eligibility criteria \cite{wang2017classifying, ross2010analysis}. Perhaps most importantly, to the best of our knowledge, only one previous work has been tested in terms of matching patients enrolled in actual clinical trials \cite{zhang2020deepenroll}, and none have been directly compared to the capabilities of a human database programmer.

\subsection*{Key Contributions}

We introduce the LeafAI query engine, an application capable of generating database queries for cohort discovery from free-text eligibility criteria. This work contributes the following:

\begin{enumerate}
    \item{A novel database annotation schema and mapping method to enable \textbf{data model-agnostic} query generation from natural language.}
    \item{Methods for transforming and leveraging \textbf{intermediate logical representations} of eligibility criteria.}
    \item{A \textbf{corpus of human-annotated logical forms of eligibility criteria} available to the research community\footnote{Will be made available upon article acceptance}.}
    \item{Methods for dynamically \textbf{reasoning upon non-specific criteria} using an integrated knowledge base of biomedical concepts.}
    \item{An evaluation of system performance by \textbf{direct comparison to that of a human database programmer} on actual clinical trial enrollments}.
\end{enumerate}

\end{document}